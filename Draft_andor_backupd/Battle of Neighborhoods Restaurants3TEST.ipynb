{"cells": [{"metadata": {"collapsed": true}, "cell_type": "markdown", "source": "## Imports"}, {"metadata": {}, "cell_type": "code", "source": "import io\nimport re\nimport json\nimport string\nimport requests\nimport numpy as np\nimport pandas as pd\n\nfrom bs4 import BeautifulSoup\nimport matplotlib.colors as colors\nfrom pandas.io.json import json_normalize\n\n# graphing \nimport matplotlib as mpl\nimport matplotlib.cm as cm\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import NullFormatter\n%matplotlib inline\n", "execution_count": 53, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Install Imports then Import them!"}, {"metadata": {}, "cell_type": "code", "source": "# import folium if cant install then import\ntry:\n    import folium\nexcept:\n    !pip install folium\n    print(\"installed {}\".format('folium'))\n    import folium\n    \n# import wikipedia if cant install then import\ntry:\n    import wikipedia as wp\nexcept:\n    !pip install wikipedia\n    print(\"installed {}\".format('wikipedia'))\n    import wikipedia\n\n# zip code stuff\ntry:\n    import uszipcode\nexcept:\n    !pip install uszipcode\n    print(\"installed {}\".format('uszipcode'))\n    import uszipcode\n    \nfrom uszipcode import Zipcode\nfrom uszipcode import SearchEngine\nsearch = SearchEngine(simple_zipcode=True)\n\n# graph imports \ntry:\n    import geopy \n    from geopy.geocoders import Nominatim\nexcept:\n    !pip install geopy\n    print(\"installed {}\".format('geopy'))\n    import geopy \n    from geopy.geocoders import Nominatim\n\n# learn imports\ntry:\n    import seaborn as sns\nexcept:\n    !pip install seaborn\n    print(\"installed {}\".format('seaborn'))\n    import seaborn as sns\n    \nfrom sklearn.cluster import KMeans\n", "execution_count": 16, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Math imports "}, {"metadata": {}, "cell_type": "code", "source": "from statistics import mode\nfrom statistics import mean\nfrom statistics import median", "execution_count": 194, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Math Functions"}, {"metadata": {}, "cell_type": "code", "source": "# gets the median\ndef getMedian(val):\n    out = median(val)\n    return out\n\n# gets the mode\ndef getMode(val):\n    out = mode(val)\n    return out\n\n# gets the mean\ndef getMean(val):\n    out = mean(val)\n    return out\n\n# get the average\ndef getAverage(val):\n    count = len(val)-1\n    added = 0\n    for v in val:\n        added += v\n    out = added / count\n    return out", "execution_count": 204, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "test1 = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]\n\ngetMedian(test1)", "execution_count": 206, "outputs": [{"output_type": "execute_result", "execution_count": 206, "data": {"text/plain": "8.5"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "### Declare City List"}, {"metadata": {}, "cell_type": "code", "source": "\"\"\"\nGet the 4 surrounding counties and 4 of the biggest cities in the state to get\na model to train the data to predict the growth of population over than next 10 years\n\"\"\"\n# this city list is the live data\ncity_list = [\n    'Baltimore',\n    'Baltimore County',\n    'Richmond',\n    'Henrico County',\n    'Phoenix',\n    'Maricopa County',\n    'Houston',\n    'Harris County'\n]\n\n# this city list is the test and train data\ncity_list_other = {\n    'Baltimore':{\n        'Counties':['Prince Georges', 'Calvert'],\n        'Counties_cords':[[38.83, -76.85], [38.53, -76.53]],\n        'Counties_wiki_page':[\"Prince George's County, Maryland\", 'Calvert County, Maryland'],\n        'Counties_pop_table_num':[4, 3],\n        'Cities':['Columbia', 'Germantown'],\n        'Cities_cords':[[39.203611, -76.856944], [39.183333, -77.266667]],\n        'Cities_wiki_page':['Columbia, Maryland', 'Germantown, Maryland'],\n        'Cities_pop_table_num':[2, 2],\n        'State': 'Maryland'\n    },\n    \"Richmond\":{\n        'Counties':['Fairfax', 'Alexandria'],\n        'Counties_cords':[[38.83, -77.28], [38.804722, -77.047222]],\n        'Counties_wiki_page':['Fairfax County, Virginia', 'Alexandria, Virginia'],\n        'Counties_pop_table_num':[6, 1],\n        'Cities':['Virginia Beach', 'Norfolk'],\n        'Cities_cords':[[36.85, -75.977778], [36.916667, -76.2]],\n        'Cities_wiki_page':['Virginia Beach, Virginia', 'Norfolk, Virginia'],\n        'Cities_pop_table_num':[3, 2],\n        'State': 'Virginia'\n    },\n    \"Phoenix\":{\n        'Counties':['La Paz', 'Yuma'],\n        'Counties_cords':[[33.840278, -113.942778], [32.786944, -113.982778]],\n        'Counties_wiki_page':['La Paz County, Arizona', 'Yuma County, Arizona'],\n        'Counties_pop_table_num':[1, 3],\n        'Cities':['Tucson', 'Mesa'],\n        'Cities_cords':[[32.221667, -110.926389], [33.422222, -111.822778]],\n        'Cities_wiki_page':['Tucson, Arizona', 'Mesa, Arizona'],\n        'Cities_pop_table_num':[2, 4],\n        'State': 'Arizona'\n    },\n    \"Houston\":{\n        'Counties':['Brazoria', 'Montgomery'],\n        'Counties_cords':[[29.17, -95.44], [30.3, -95.5]],\n        'Counties_wiki_page':['Brazoria County, Texas', 'Montgomery County, Texas'],\n        'Counties_pop_table_num':[1, 1],\n        'Cities':['Dallas', 'Arlington'],\n        'Cities_cords':[[32.779167, -96.808889], [32.705, -97.122778]],\n        'Cities_wiki_page':['Dallas', 'Arlington, Texas'],\n        'Cities_pop_table_num':[5, 2],\n        'State': 'Texas'\n    }\n}\n\ncity_list_other = pd.DataFrame.from_dict(city_list_other) #, orient='index')", "execution_count": 38, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "city_list_other['Baltimore'].keys()\n", "execution_count": 40, "outputs": [{"output_type": "execute_result", "execution_count": 40, "data": {"text/plain": "Index(['Cities', 'Cities_cords', 'Cities_pop_table_num', 'Cities_wiki_page',\n       'Counties', 'Counties_cords', 'Counties_pop_table_num',\n       'Counties_wiki_page', 'State'],\n      dtype='object')"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "### Get Testing Data Function"}, {"metadata": {}, "cell_type": "code", "source": "\"\"\"\nwikiName = name of the wiki page, is a string\ndataL = the data location of the table, is a int\n\"\"\"\ndef getPop(wikiName, dataL):\n    s = \"1234567890.%\" # this gets rid of weird chars\n    s2 = '1234567890'\n    html = wp.page(wikiName).html().encode('UTF-8')\n    print('Got the {} page'.format(wikiName))\n    \n    df = pd.read_html(html)[dataL]\n    print(df.keys())\n    k = df.keys()\n    \n    cen = df['Historical population']['Census'] # census year\n    pop = df['Historical population']['Pop.'] # population\n    perc = df['Historical population']['%\u00c2\u00b1'] # percent change\n    \n    # NDF = new dataframe\n    NDF = {\n        'Census': cen,\n        '{}-pop'.format(wikiName): pop,\n        'Percent': perc \n    }\n\n    # convert to a better dataframe\n    dataOut = pd.DataFrame(NDF, columns = [\"Census\", '{}-pop'.format(wikiName), \"Percent\"])\n    \n    # delete the first and last row\n    dataOut = dataOut.drop([len(dataOut)-1])\n    dataOut = dataOut.drop([0])\n\n    printable = set(string.printable)\n    \n    for index, row in dataOut.iterrows():\n        row['Percent'] = singleToFloat(''.join(filter(lambda x: x in printable, row['Percent'])))\n        if type(row['Census']) != int:\n            row['Census'] = row['Census'].strip('Est. ')\n    \n    return dataOut\n\n# does the same thing as the for loop above but before its added to the DF\ndef stripAndFix(per):\n    print(per)\n    s = \"1234567890.%\" # this gets rid of weird chars\n    printable = set(string.printable)\n    \n    out = []\n    \n    for p in per:\n        out.append(''.join(filter(lambda x: x in printable, p)))\n    return out", "execution_count": 282, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Get the Testing Data: Baltimore"}, {"metadata": {}, "cell_type": "code", "source": "# list format == [[wiki_page, location], ... ]\n\nALL_DFs = [] # all dataframe will be added to this list.\n\nt1 = city_list_other['Baltimore']['Counties_wiki_page']\nt2 = city_list_other['Baltimore']['Counties_pop_table_num']\nt3 = city_list_other['Baltimore']['Cities_wiki_page']\nt4 = city_list_other['Baltimore']['Cities_pop_table_num']\n\nml =[\n    [t1[0], t2[0]],\n    [t1[1], t2[1]],\n    [t3[0], t4[0]],\n    [t3[1], t4[1]],\n]\n\nfor m in ml:\n    tDF = getPop(m[0],m[1])\n    ALL_DFs.append(tDF)\n\n# all population names will be wiki-page-pop", "execution_count": 368, "outputs": [{"output_type": "stream", "text": "Got the Prince George's County, Maryland page\nMultiIndex(levels=[['Historical population'], ['%\u00c2\u00b1', 'Census', 'Pop.', 'Unnamed: 2_level_1']],\n           codes=[[0, 0, 0, 0], [1, 2, 3, 0]])\nGot the Calvert County, Maryland page\nMultiIndex(levels=[['Historical population'], ['%\u00c2\u00b1', 'Census', 'Pop.', 'Unnamed: 2_level_1']],\n           codes=[[0, 0, 0, 0], [1, 2, 3, 0]])\nGot the Columbia, Maryland page\nMultiIndex(levels=[['Historical population'], ['%\u00c2\u00b1', 'Census', 'Pop.', 'Unnamed: 2_level_1']],\n           codes=[[0, 0, 0, 0], [1, 2, 3, 0]])\nGot the Germantown, Maryland page\nMultiIndex(levels=[['Historical population'], ['%\u00c2\u00b1', 'Census', 'Pop.', 'Unnamed: 2_level_1']],\n           codes=[[0, 0, 0, 0], [1, 2, 3, 0]])\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "ALL_DFs[0]", "execution_count": 278, "outputs": [{"output_type": "execute_result", "execution_count": 278, "data": {"text/plain": "   Census Prince George's County, Maryland-pop Percent\n1    1800                                21175   0.008\n2    1810                                20589   0.028\n3    1820                                20216   0.018\n4    1830                                20474   0.013\n5    1840                                19539   0.046\n6    1850                                21549   0.103\n7    1860                                23327   0.083\n8    1870                                21138   0.094\n9    1880                                26451   0.251\n10   1890                                26080   0.014\n11   1900                                29898   0.146\n12   1910                                36147   0.209\n13   1920                                43347   0.199\n14   1930                                60095   0.386\n15   1940                                89490   0.489\n16   1950                               194182    1.17\n17   1960                               357395   0.841\n18   1970                               660567   0.848\n19   1980                               665071   0.007\n20   1990                               729268   0.097\n21   2000                               801515   0.099\n22   2010                               863420   0.077\n23   2019                               909327   0.053", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Census</th>\n      <th>Prince George's County, Maryland-pop</th>\n      <th>Percent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>1800</td>\n      <td>21175</td>\n      <td>0.008</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1810</td>\n      <td>20589</td>\n      <td>0.028</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1820</td>\n      <td>20216</td>\n      <td>0.018</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1830</td>\n      <td>20474</td>\n      <td>0.013</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1840</td>\n      <td>19539</td>\n      <td>0.046</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1850</td>\n      <td>21549</td>\n      <td>0.103</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1860</td>\n      <td>23327</td>\n      <td>0.083</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1870</td>\n      <td>21138</td>\n      <td>0.094</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1880</td>\n      <td>26451</td>\n      <td>0.251</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1890</td>\n      <td>26080</td>\n      <td>0.014</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1900</td>\n      <td>29898</td>\n      <td>0.146</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1910</td>\n      <td>36147</td>\n      <td>0.209</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>1920</td>\n      <td>43347</td>\n      <td>0.199</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>1930</td>\n      <td>60095</td>\n      <td>0.386</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>1940</td>\n      <td>89490</td>\n      <td>0.489</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>1950</td>\n      <td>194182</td>\n      <td>1.17</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>1960</td>\n      <td>357395</td>\n      <td>0.841</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>1970</td>\n      <td>660567</td>\n      <td>0.848</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>1980</td>\n      <td>665071</td>\n      <td>0.007</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>1990</td>\n      <td>729268</td>\n      <td>0.097</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>2000</td>\n      <td>801515</td>\n      <td>0.099</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>2010</td>\n      <td>863420</td>\n      <td>0.077</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>2019</td>\n      <td>909327</td>\n      <td>0.053</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "### Get the Testing Data: Richmond"}, {"metadata": {}, "cell_type": "code", "source": "t1 = city_list_other['Richmond']['Counties_wiki_page']\nt2 = city_list_other['Richmond']['Counties_pop_table_num']\nt3 = city_list_other['Richmond']['Cities_wiki_page']\nt4 = city_list_other['Richmond']['Cities_pop_table_num']\n\nml =[\n    [t1[0], t2[0]],\n    [t1[1], t2[1]],\n    #[t3[0], t4[0]],\n    [t3[1], t4[1]]\n]\n\nfor m in ml:\n    tDF = getPop(m[0],m[1])\n    ALL_DFs.append(tDF)\n\n# all population names will be wiki-page-pop\nbody = client_b8dd31888675478381adf80bd9d2a977.get_object(Bucket='battleofneighborhoodsrestaurants-donotdelete-pr-rr6vu0kgfnvrbj',Key='norfolk2_pop.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\nnorfolk = pd.read_csv(body)\nALL_DFs.append(norfolk)", "execution_count": 369, "outputs": [{"output_type": "stream", "text": "Got the Fairfax County, Virginia page\nMultiIndex(levels=[['Historical population'], ['%\u00c2\u00b1', 'Census', 'Pop.', 'Unnamed: 2_level_1']],\n           codes=[[0, 0, 0, 0], [1, 2, 3, 0]])\nGot the Alexandria, Virginia page\nMultiIndex(levels=[['Historical population'], ['%\u00c2\u00b1', 'Census', 'Pop.', 'Unnamed: 2_level_1']],\n           codes=[[0, 0, 0, 0], [1, 2, 3, 0]])\nGot the Norfolk, Virginia page\nMultiIndex(levels=[['Historical population'], ['%\u00c2\u00b1', 'Census', 'Pop.', 'Unnamed: 2_level_1']],\n           codes=[[0, 0, 0, 0], [1, 2, 3, 0]])\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "### Get the Testing Data: Phoenix"}, {"metadata": {}, "cell_type": "code", "source": "t1 = city_list_other['Phoenix']['Counties_wiki_page']\nt2 = city_list_other['Phoenix']['Counties_pop_table_num']\nt3 = city_list_other['Phoenix']['Cities_wiki_page']\nt4 = city_list_other['Phoenix']['Cities_pop_table_num']\n\nml =[\n    [t1[0], t2[0]],\n    [t1[1], t2[1]],\n    [t3[0], t4[0]],\n    [t3[1], t4[1]]\n]\n\nfor m in ml:\n    tDF = getPop(m[0],m[1])\n    ALL_DFs.append(tDF)\n\n# all population names will be wiki-page-pop", "execution_count": 370, "outputs": [{"output_type": "stream", "text": "Got the La Paz County, Arizona page\nMultiIndex(levels=[['Historical population'], ['%\u00c2\u00b1', 'Census', 'Pop.', 'Unnamed: 2_level_1']],\n           codes=[[0, 0, 0, 0], [1, 2, 3, 0]])\nGot the Yuma County, Arizona page\nMultiIndex(levels=[['Historical population'], ['%\u00c2\u00b1', 'Census', 'Pop.', 'Unnamed: 2_level_1']],\n           codes=[[0, 0, 0, 0], [1, 2, 3, 0]])\nGot the Tucson, Arizona page\nMultiIndex(levels=[['Historical population'], ['%\u00c2\u00b1', 'Census', 'Pop.', 'Unnamed: 2_level_1']],\n           codes=[[0, 0, 0, 0], [1, 2, 3, 0]])\nGot the Mesa, Arizona page\nMultiIndex(levels=[['Historical population'], ['%\u00c2\u00b1', 'Census', 'Pop.', 'Unnamed: 2_level_1']],\n           codes=[[0, 0, 0, 0], [1, 2, 3, 0]])\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "### Get the Testing Data: Houston"}, {"metadata": {}, "cell_type": "code", "source": "t1 = city_list_other['Houston']['Counties_wiki_page']\nt2 = city_list_other['Houston']['Counties_pop_table_num']\nt3 = city_list_other['Houston']['Cities_wiki_page']\nt4 = city_list_other['Houston']['Cities_pop_table_num']\n\nml =[\n    [t1[0], t2[0]],\n    [t1[1], t2[1]],\n    [t3[0], t4[0]],\n    [t3[1], t4[1]]\n]\n\nfor m in ml:\n    tDF = getPop(m[0],m[1])\n    ALL_DFs.append(tDF)\n\n# all population names will be wiki-page-pop", "execution_count": 374, "outputs": [{"output_type": "stream", "text": "Got the Brazoria County, Texas page\nMultiIndex(levels=[['Historical population'], ['%\u00c2\u00b1', 'Census', 'Pop.', 'Unnamed: 2_level_1']],\n           codes=[[0, 0, 0, 0], [1, 2, 3, 0]])\nGot the Montgomery County, Texas page\nMultiIndex(levels=[['Historical population'], ['%\u00c2\u00b1', 'Census', 'Pop.', 'Unnamed: 2_level_1']],\n           codes=[[0, 0, 0, 0], [1, 2, 3, 0]])\nGot the Dallas page\nMultiIndex(levels=[['Historical population'], ['%\u00c2\u00b1', 'Census', 'Pop.', 'Unnamed: 2_level_1']],\n           codes=[[0, 0, 0, 0], [1, 2, 3, 0]])\nGot the Arlington, Texas page\nMultiIndex(levels=[['Historical population'], ['%\u00c2\u00b1', 'Census', 'Pop.', 'Unnamed: 2_level_1']],\n           codes=[[0, 0, 0, 0], [1, 2, 3, 0]])\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "### Clustering Functions"}, {"metadata": {}, "cell_type": "code", "source": "def makeCluster(cl):\n    header = ['Census']\n    hp2 = ['Percent1', \"Percent2\", 'Percent3', 'Percent4']\n    keys = [] # takes the column name from the population\n    keyObjects = [] # will take the list from the population dataframe\n    difPer = [] # all the different percent changes\n    \n    for c in cl:\n        tk = c.keys()\n        header.append(tk[1])\n        keys.append(tk[1])\n        temppop = c[tk[1]] # this migh need to be changed to a index val\n        tempper = c['Percent']\n        keyObjects.append(temppop)\n        difPer.append(tempper)\n        \n    for h in hp2:\n        header.append(h)\n        \n    CL = {\n        'Census': list(cl[0]['Census']), # this is uniform\n        header[1]: keyObjects[0],\n        header[2]: keyObjects[1],\n        header[3]: keyObjects[2],\n        header[4]: keyObjects[3],\n        hp2[0]: difPer[0],\n        hp2[1]: difPer[1],\n        hp2[2]: difPer[2],\n        hp2[3]: difPer[3]\n    }\n    \n    CL = pd.DataFrame(CL, columns = header)\n    return CL\n    ", "execution_count": 150, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Clean the Data OLD"}, {"metadata": {}, "cell_type": "code", "source": "# this function just gets the common range || as a string\ndef makeYearRangeSTR():\n    start = 1800\n    end = 2020\n    nums = []\n    for i in range(start, end, 10):\n        nums.append(str(i))\n    nums.append('2019')\n    return nums\n\n# this function just gets the common range || as a int\ndef makeYearRangeINT():\n    start = 1800\n    end = 2020\n    nums = []\n    for i in range(start, end, 10):\n        nums.append(i)\n    nums.append('2019')\n    return nums\n\ndef getListOfZeroI(): # ints\n    s = 0\n    e = 23\n    z = []\n    for i in range(s,e, 1):\n        z.append(0)\n    return z\n\ndef getListOfZeroS(): # strings\n    s = 0\n    e = 23\n    z = []\n    for i in range(s,e, 1):\n        z.append(str(0))\n    return z\n\ndef getListOfZeroF(): # float\n    s = 0\n    e = 23\n    z = []\n    for i in range(s,e, 1):\n        z.append(float(0.0))\n    return z\n\ndef turnToFloat(per): # turns the value to a decimial, list\n    convert = []\n    for p in per:\n        p = p.strip('%')\n        convert.append(float(p)/100)\n    return convert # set this equal in a for loop\n\ndef singleToFloat(val): # turns the value to a decimial, single val\n    val = val.strip('%')\n    return float(val)/100\n\ndef getChangePer(per): # get the percent change\n    index = []\n    for i in range(1, len(per)-1):\n        index.append(i)\n        \n    periods = 23 - len(per)\n    per = {\n        #'index': index,\n        'Percent': per\n    }\n    per = pd.DataFrame(per, columns=['Percent'])\n    print(per.pct_change(periods = periods, axis=1))\n\n    \ndef addMissingYear(df): # does this in the Census column\n    oldL = list(df['Census'])\n    refY = makeYearRangeSTR()\n    toAdd = np.setdiff1d(refY, oldL)\n    \n    # get index locations\n    IL = []\n    for a in list(oldL):\n        IL.append(refY.index(a))\n    \n    #print(toAdd)\n    #print(IL)\n    return toAdd, IL, refY\n\ndef cleanData1(cl): # takes the data set and normalizes \n    yearRange = makeYearRangeSTR()\n    header = ['Census']\n    hp2 = ['Percent1', \"Percent2\", 'Percent3', 'Percent4']\n    keys = [] # takes the column name from the population\n    keyObjects = [] # will take the population dataframe\n    difPer = [] # all the different percent changes\n    yr = [] # this will take all the years that the census took place\n    \n    tk = cl.keys()\n    for c in cl:\n        \n        #header.append(tk[1])\n        #keys.append(tk[1])\n        temppop = c[1] # this migh need to be changed to a index val\n        tempper = c[2]\n        yr.append(c[0])\n        keyObjects.append(1)\n        difPer.append(tempper)\n    \n    needsClean = False\n    x = 0\n    #for k1 in yr: # the population, k1 is a ( one )\n    if len(yr) != len(yearRange):\n        needsClean = True\n        #print('index {} has errors\\n {} |vs| {}'.format(x, len(yr), len(yearRange)))\n        #print('\\n the differs \\n')\n        #print(set(k1) - set(yearRange))\n        #print([item for item in yearRange if item not in k1])\n        #x += 1\n\n    if needsClean == True:\n        process1(cl)\n\ndef process1(df):\n    toAdd, IL, refY = addMissingYear(df)\n    szi = getListOfZeroI()\n    szs = getListOfZeroS()\n    szf = getListOfZeroF()\n    \n    keys = list(df.keys())\n    print(type(df))\n    pop = df[key[1]]\n    per = df[k]\n    \n    l1 = szs\n    l2 = szi # pop\n    l3 = szf # percent\n    \n    x = 0\n    for i in IL:\n        l2[i] = pop[x]\n        if type(per[x]) == float:\n            l3[i] = singleToFloat(per[x])\n        else:\n            l3[i] = per[x]\n        x += 1\n    \n    print(l2, '\\n', l3)", "execution_count": 358, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "print(len(makeYearRangeSTR()))", "execution_count": 207, "outputs": [{"output_type": "stream", "text": "23\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "### Create Clusters "}, {"metadata": {}, "cell_type": "code", "source": "# baltimore cluster\nBC = ALL_DFs[0:1]\n#BC.append(ALL_DFs[])\n\n# richmand cluster\nRC = ALL_DFs[4:7]\n\n# phoenix cluster\nPC = ALL_DFs[8:12]\n\n# Houston cluster\nHC = ALL_DFs[12:16]", "execution_count": 371, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "x = 0\ngd = [] # good data\naddL = [0, 1, 4, 5, 6, 7, 9, 10, 12, 13, 15]\nprint(len(addL))\nfor a in ALL_DFs:\n    #print('{} || {}'.format(x, len(a)))\n    #print('\\n\\n\\n')\n    #print(a)\n    if x in addL:\n        gd.append(a)\n    x += 1\n    \nprint(len(gd))", "execution_count": 376, "outputs": [{"output_type": "stream", "text": "11\n11\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "### TESTING"}, {"metadata": {}, "cell_type": "code", "source": "t1 = ALL_DFs[0:4]\nfor t in t1:\n    cleanData1[t]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#k = ALL_DFs[0].keys()\n#BC[1]['Census']\n#list(BC[0]['Census'])\n#k[1]\n#makeCluster(BC)\n#BC[1]['Census']\n#BC[0].head()\n#for b in BC:\n#    print(b)\n#getChangePer(list(BC[2]['Census']))\n#type(list(BC[1]['Census']))\n#t = list(BC[2]['Percent'])\ntemp = ALL_DFs[2]\ncleanData1(temp)\n#temp\n#toAdd, IL, refY = addMissingYear(temp)\n#print(temp['Census'])\n#temp['Census'] = refY\n#addZeros(temp, IL, toAdd)\n#IL", "execution_count": 359, "outputs": [{"output_type": "stream", "text": "<class 'pandas.core.frame.DataFrame'>\n", "name": "stdout"}, {"output_type": "error", "ename": "KeyError", "evalue": "1", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)", "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2655\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2656\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2657\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n", "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n", "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n", "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n", "\u001b[0;31mKeyError\u001b[0m: 1", "\nDuring handling of the above exception, another exception occurred:\n", "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)", "\u001b[0;32m<ipython-input-359-34fa2c9824a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#t = list(BC[2]['Percent'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mALL_DFs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mcleanData1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m#temp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#toAdd, IL, refY = addMissingYear(temp)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m<ipython-input-358-873f5f0bbba6>\u001b[0m in \u001b[0;36mcleanData1\u001b[0;34m(cl)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mneedsClean\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mprocess1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprocess1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m<ipython-input-358-873f5f0bbba6>\u001b[0m in \u001b[0;36mprocess1\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0mpop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m     \u001b[0mper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2926\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2927\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2656\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2657\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2658\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2659\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n", "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n", "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n", "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n", "\u001b[0;31mKeyError\u001b[0m: 1"]}]}, {"metadata": {}, "cell_type": "markdown", "source": "### Load Baltimore Population"}, {"metadata": {}, "cell_type": "code", "source": "import types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\nclient_b8dd31888675478381adf80bd9d2a977 = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='rEw1LED0Rb2Cxl_9pbLj1c8XzOq1v7pwSa_vOCrhYiVu',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3-api.us-geo.objectstorage.service.networklayer.com')\n\nbody = client_b8dd31888675478381adf80bd9d2a977.get_object(Bucket='battleofneighborhoodsrestaurants-donotdelete-pr-rr6vu0kgfnvrbj',Key='balt_pop.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\nbalt_pop = pd.read_csv(body)\n#balt_pop.head()", "execution_count": 9, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Load Richmond Population"}, {"metadata": {}, "cell_type": "code", "source": "body = client_b8dd31888675478381adf80bd9d2a977.get_object(Bucket='battleofneighborhoodsrestaurants-donotdelete-pr-rr6vu0kgfnvrbj',Key='rich_pop.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\nrich_pop = pd.read_csv(body)\n#rich_pop.head()", "execution_count": 10, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Load Houston Population"}, {"metadata": {}, "cell_type": "code", "source": "body = client_b8dd31888675478381adf80bd9d2a977.get_object(Bucket='battleofneighborhoodsrestaurants-donotdelete-pr-rr6vu0kgfnvrbj',Key='hou_pop.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\nhou_pop = pd.read_csv(body)\n#hou_pop.head()", "execution_count": 12, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Load Phoenix Population"}, {"metadata": {}, "cell_type": "code", "source": "body = client_b8dd31888675478381adf80bd9d2a977.get_object(Bucket='battleofneighborhoodsrestaurants-donotdelete-pr-rr6vu0kgfnvrbj',Key='phx_pop.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\nphx_pop = pd.read_csv(body)\n#phx_pop.head()", "execution_count": 14, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}